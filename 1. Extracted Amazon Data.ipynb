{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bc998c-b4f8-4285-bc01-743ea0baa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa0af4b-6e17-48a2-8599-0aee4e624822",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a62a50-cc45-48f7-bdc7-fa8af92348f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f773ae4-c95d-4767-8f61-067c995d9ab4",
   "metadata": {},
   "source": [
    "## 🔐 Automating Amazon Login Using Selenium\r\n",
    "\r\n",
    "This script automates the login process on Amazon.in using Selenium WebDriver. It opens the login page, enters the phone number and password with human-like delays, and clicks the necessary buttons (Continue and Sign-In) to complete the login process.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15771bd-64de-417a-9f10-bcd3c0c95911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Phone/email entered.\n",
      "✅ Clicked Continue.\n",
      "✅ Password entered.\n",
      "✅ Clicked Sign-In.\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "\n",
    "phone_no = \"1234567890\"\n",
    "password = \"xyz\"\n",
    "\n",
    "login_link = \"https://www.amazon.in/ap/signin?openid.pape.max_auth_age=0&openid.return_to=https%3A%2F%2Fwww.amazon.in%2F%3Fref_%3Dnav_signin&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=inflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0\"\n",
    "\n",
    "browser.get(login_link)\n",
    "\n",
    "wait = WebDriverWait(browser, 15)\n",
    "actions = ActionChains(browser)\n",
    "\n",
    "def slow_type(element, text, delay_range=(0.05, 0.15)):\n",
    "    for char in text:\n",
    "        element.send_keys(char)\n",
    "        time.sleep(random.uniform(*delay_range))\n",
    "\n",
    "wait.until(EC.presence_of_element_located((By.ID, 'authportal-main-section')))\n",
    "time.sleep(random.uniform(1.5, 3))\n",
    "\n",
    "try:\n",
    "    try:\n",
    "        email_input = wait.until(EC.visibility_of_element_located((By.ID, 'ap_email')))\n",
    "    except:\n",
    "        email_input = wait.until(EC.visibility_of_element_located((By.ID, 'ap_email_login')))\n",
    "        \n",
    "    email_input.click()\n",
    "    time.sleep(random.uniform(0.2, 0.5))\n",
    "    email_input.clear()\n",
    "    slow_type(email_input, phone_no)\n",
    "    print(\"✅ Phone/email entered.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Could not enter phone/email:\", e)\n",
    "\n",
    "time.sleep(random.uniform(1.5, 3))\n",
    "\n",
    "try:\n",
    "    continue_btn = wait.until(EC.element_to_be_clickable((By.ID, 'continue')))\n",
    "    continue_btn.click()\n",
    "    print(\"✅ Clicked Continue.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Failed to click Continue:\", e)\n",
    "\n",
    "time.sleep(random.uniform(1.5, 3))\n",
    "\n",
    "try:\n",
    "    password_input = wait.until(EC.visibility_of_element_located((By.ID, 'ap_password')))\n",
    "    password_input.click()\n",
    "    time.sleep(random.uniform(0.2, 0.5))\n",
    "    password_input.clear()\n",
    "    slow_type(password_input, password)\n",
    "    print(\"✅ Password entered.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Could not enter password:\", e)\n",
    "\n",
    "time.sleep(random.uniform(1.5, 3))\n",
    "\n",
    "try:\n",
    "    sign_in_button = wait.until(EC.element_to_be_clickable((By.ID, 'signInSubmit')))\n",
    "    actions.move_to_element(sign_in_button).pause(0.3).click().perform()\n",
    "    print(\"✅ Clicked Sign-In.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Could not click Sign-In:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbea6c-f5c7-42db-8c81-cf693eff655e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd2e798-d4b4-48b1-bea5-d39990b6a019",
   "metadata": {},
   "source": [
    "## 📦 Scraping Product and Review Data from Amazon.in\r\n",
    "\r\n",
    "This script automates the process of:\r\n",
    "\r\n",
    "1. Taking a product name input (e.g., \"mobile\", \"laptop\") from the user.\r\n",
    "2. Opening the Amazon search results page and listing available brands.\r\n",
    "3. Letting the user select one or more brands to filter.\r\n",
    "4. Navigating through all pages of product listings for the selected brand(s).\r\n",
    "5. Visiting each product page to extract product details like title, price, rating, ASIN, model number, etc.\r\n",
    "6. Opening the review section and scraping all reviews with metadata (rating, title, text, date, etc.).\r\n",
    "7. Saving all collected data into a list for further processing.\r\n",
    "\r\n",
    "It uses **Selenium** for browser automation and **BeautifulSoup** for parsing HTML content.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6768f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_detail_list = []\n",
    "visited_review_links = set()\n",
    "\n",
    "\n",
    "last_page = 1\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        search_item = input(\"Enter product you want to search (like Mobile, laptop ....) - \").strip()\n",
    "        if search_item.replace(\" \", \"\").isalpha():\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Enter a valid search item (letters and spaces only).\")\n",
    "            time.sleep(random.uniform(0.8, 1.4))  # simulating rethinking time\n",
    "    \n",
    "    time.sleep(random.uniform(1.5, 2.5))\n",
    "    first_url = 'https://www.amazon.in/s?k=' + search_item\n",
    "    browser.get(first_url)\n",
    "\n",
    "    scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "    max_scrolls = 10\n",
    "    \n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    for _ in range(max_scrolls):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "    soup.find()\n",
    "    \n",
    "    try:\n",
    "        filter_phone_brands = soup.find('div', id=\"brandsRefinements\") \\\n",
    "                                   .find('ul', id=\"filter-p_123\") \\\n",
    "                                   .find_all('span', attrs={\"role\": \"presentation\"})\n",
    "        \n",
    "        avl_brands = []\n",
    "        avl_brands.append([\"0\", \"all\", first_url])\n",
    "    \n",
    "        i_x = 1\n",
    "        for brand in filter_phone_brands[1:]:\n",
    "            brand_name = brand.find('a').text.strip()\n",
    "            updated_url = \"https://www.amazon.in\" + brand.find('a').get('href')\n",
    "            avl_brands.append([str(i_x), brand_name, updated_url])\n",
    "            i_x += 1\n",
    "    \n",
    "        brand_df = pd.DataFrame(data=avl_brands, columns=['Index', \"Brand Name\", \"Url\"])\n",
    "    \n",
    "        print(\"\\n✅ You can search by Index or Brand Name\\n\")\n",
    "        print(brand_df[['Index', \"Brand Name\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "        brand_name_list = [name.lower() for name in brand_df['Brand Name'].to_list()]\n",
    "\n",
    "    \n",
    "        while True:\n",
    "            user_input = input(\"\\nEnter Index or Brand Name you want to search - \").strip()\n",
    "\n",
    "            user_input_split = list(set(user_input.split(',')))\n",
    "            \n",
    "\n",
    "            if len(user_input_split) > 1:\n",
    "                \n",
    "                if (all(val.strip() in brand_df['Index'].to_list() for val in user_input_split) or all(val.strip().lower() in brand_name_list for val in user_input_split)):\n",
    "\n",
    "\n",
    "                    if user_input_split[0].strip().isdigit():\n",
    "                        match = brand_df[brand_df['Index'] == user_input_split[0].strip()]\n",
    "                        print(\"Brand Name - \",brand_df[brand_df['Index'] == user_input_split[0].strip()]['Brand Name'].values[0])\n",
    "                        final_url = match['Url'].values[0]\n",
    "                        \n",
    "                    else:\n",
    "                        match = brand_df[brand_df['Brand Name'].str.lower() == user_input_split[0].strip().lower()]\n",
    "                        print(\"Brand Name - \",user_input_split[0].strip())\n",
    "                        final_url = match['Url'].values[0]\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    for single_input in user_input_split[1:]:\n",
    "                        browser.get(final_url)\n",
    "    \n",
    "                        scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "                        max_scrolls = 10\n",
    "                        \n",
    "                        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                        \n",
    "                        for _ in range(max_scrolls):\n",
    "                            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                            time.sleep(scroll_pause_time)\n",
    "                            new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                            if new_height == last_height:\n",
    "                                break\n",
    "                            last_height = new_height\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        ini_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                        if single_input.strip().isdigit():\n",
    "                            search_brand_name = brand_df[brand_df['Index'] == single_input.strip()]['Brand Name'].values[0]\n",
    "\n",
    "                            loop_brand_search = ini_soup.find('div', id=\"brandsRefinements\") \\\n",
    "                                   .find('ul', id=\"filter-p_123\") \\\n",
    "                                   .find_all('span', attrs={\"role\": \"presentation\"})\n",
    "                            \n",
    "                            for search_brand in loop_brand_search[1:]:\n",
    "                                brand_name = search_brand.find('a').text.strip()\n",
    "                                if brand_name.lower() == search_brand_name.strip().lower():\n",
    "                                    print(\"Brand Name - \",brand_name)\n",
    "                                    final_url = \"https://www.amazon.in\" + search_brand.find('a').get('href')\n",
    "                                    break\n",
    "\n",
    "                        else:\n",
    "                            loop_brand_search = ini_soup.find('div', id=\"brandsRefinements\") \\\n",
    "                                   .find('ul', id=\"filter-p_123\") \\\n",
    "                                   .find_all('span', attrs={\"role\": \"presentation\"})\n",
    "                            \n",
    "                            for search_brand in loop_brand_search[1:]:\n",
    "                                brand_name = search_brand.find('a').text.strip()\n",
    "                                if brand_name.lower() == single_input.strip().lower():\n",
    "                                    print(\"Brand Name - \",brand_name)\n",
    "                                    final_url = \"https://www.amazon.in\" + search_brand.find('a').get('href')\n",
    "                                    break\n",
    "                    break\n",
    "          \n",
    "                else:\n",
    "                    print(\"❌ Invalid input. Please enter a valid index or brand name, all matching.\")\n",
    "\n",
    "            elif len(user_input_split) == 1:\n",
    "                if user_input.strip().isdigit():\n",
    "                    match = brand_df[brand_df['Index'] == user_input.strip()]\n",
    "                    print(\"Brand Name - \",brand_df[brand_df['Index'] == user_input.strip()]['Brand Name'].values[0])\n",
    "                    final_url = match['Url'].values[0]\n",
    "                    break\n",
    "                else:\n",
    "                    match = brand_df[brand_df['Brand Name'].str.lower() == user_input.strip().lower()]\n",
    "                    print(\"Brand Name - \",user_input.strip())\n",
    "                    final_url = match['Url'].values[0]\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                print(\"❌ Invalid input. Please enter a valid index or brand name.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Couldn't extract brand filters. Using default search URL.\")\n",
    "        final_url = first_url\n",
    "    \n",
    "    browser.get(final_url)\n",
    "    \n",
    "    scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "    max_scrolls = 10\n",
    "    \n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    for _ in range(max_scrolls):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        last_page_tag = soup.find('div', class_=\"a-section a-text-center s-pagination-container\") \\\n",
    "                        .find('span', class_=\"s-pagination-item s-pagination-disabled\")\n",
    "        if last_page_tag:\n",
    "            last_page = last_page_tag.text.strip()\n",
    "    \n",
    "        else:\n",
    "            last_page = soup.find('ul', class_=\"a-unordered-list a-horizontal s-unordered-list-accessibility\").find_all('li', recursive = False)[-2].text.strip()\n",
    "    \n",
    "    except:\n",
    "        prin(\"Goes to Last Page Except\")\n",
    "        last_page = 1\n",
    "    \n",
    "    print(\"last page\", last_page)\n",
    "    \n",
    "    for page in range(1, int(last_page) + 1):\n",
    "        post_final_url = final_url + \"&page=\" + str(page)\n",
    "        print(\"Page Url\", post_final_url)\n",
    "        browser.get(post_final_url)\n",
    "    \n",
    "        scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "        max_scrolls = 10\n",
    "        \n",
    "        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        for _ in range(max_scrolls):\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(scroll_pause_time)\n",
    "            new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "    \n",
    "        soup1 = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        try:\n",
    "            all_product = soup1.find('div', class_=\"s-main-slot s-result-list s-search-results sg-row\") \\\n",
    "                               .find_all('div', role=\"listitem\", recursive=False)\n",
    "        except:\n",
    "            prin(\"No product found.\")\n",
    "            continue\n",
    "    \n",
    "        for product in all_product:\n",
    "            try:\n",
    "                title_div = product.find('div', attrs={\"data-cy\": \"title-recipe\"})\n",
    "                all_links = title_div.find_all('a')\n",
    "                \n",
    "                product_link = None\n",
    "                for p_link in all_links:\n",
    "                    href = p_link.get('href')\n",
    "                    if href and href.startswith(\"/\"):\n",
    "                        product_link = 'https://www.amazon.in' + href\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                \n",
    "                if not product_link:\n",
    "                    print(\"❌ No valid product link found in this product.\")\n",
    "                    continue\n",
    "            \n",
    "    \n",
    "    \n",
    "                browser.get(product_link)\n",
    "            \n",
    "                scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "                max_scrolls = 10\n",
    "                \n",
    "                last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                \n",
    "                for _ in range(max_scrolls):\n",
    "                    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(scroll_pause_time)\n",
    "                    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "            \n",
    "                soup2 = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "                prod_title = price = overall_rating = rating_count = bought_last_month = None\n",
    "                asin = model_number = manufacturer_name = generic_name = customer_say = insight = None\n",
    "            \n",
    "                try:\n",
    "                    prod_title = soup2.find('h1', id=\"title\").text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "                try:\n",
    "                    price = soup2.find('span', class_=\"a-price-whole\").text.strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "                try:\n",
    "                    overall_rating = soup2.find('span', attrs={\"data-hook\": \"rating-out-of-text\"}).text.split()[0].strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "                try:\n",
    "                    rating_count = soup2.find('span', attrs={\"data-hook\": \"total-review-count\"}).text.split()[0].strip()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    bought_last_month = soup2.find('span', id=\"social-proofing-faceout-title-tk_bought\").find(\"span\", class_=\"a-text-bold\").text.split()[0].strip()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "                try:\n",
    "                    for all_detail in soup2.find_all('table', class_=\"a-keyvalue prodDetTable\"):\n",
    "                        for ind_detail in all_detail.find_all('tr'):\n",
    "                            th = ind_detail.find('th')\n",
    "                            td = ind_detail.find('td')\n",
    "                            if th and td and \"asin\" in th.text.strip().lower():\n",
    "                                asin = td.text.strip()\n",
    "                                break\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    for all_detail in soup2.find_all('table', class_=\"a-keyvalue prodDetTable\"):\n",
    "                        for ind_detail in all_detail.find_all('tr'):\n",
    "                            th = ind_detail.find('th')\n",
    "                            td = ind_detail.find('td')\n",
    "                            if th and td and \"model number\" in th.text.strip().lower():\n",
    "                                model_number = td.text.strip()\n",
    "                                break\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    for all_detail in soup2.find_all('table', class_=\"a-keyvalue prodDetTable\"):\n",
    "                        for ind_detail in all_detail.find_all('tr'):\n",
    "                            th = ind_detail.find('th')\n",
    "                            td = ind_detail.find('td')\n",
    "                            if th and td and \"brand name\" in th.text.strip().lower():\n",
    "                                manufacturer_name = td.text.strip()\n",
    "                                break\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    for all_detail in soup2.find_all('table', class_=\"a-keyvalue prodDetTable\"):\n",
    "                        for ind_detail in all_detail.find_all('tr'):\n",
    "                            th = ind_detail.find('th')\n",
    "                            td = ind_detail.find('td')\n",
    "                            if th and td and \"item type\" in th.text.strip().lower():\n",
    "                                generic_name = td.text.strip()\n",
    "                                break\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    customer_say = soup2.find('div', id=\"product-summary\").find(\"p\", class_=\"a-spacing-small\").text.strip()\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    insight_soup = soup2.find(\"div\", attrs={\"data-hook\":\"cr-insights-widget-aspects\"}) \\\n",
    "                    .find('div', attrs={'aria-label': 'Commonly Mentioned Aspects'}) \\\n",
    "                    .find_all('a', recursive=False)\n",
    "                    all_insight = []\n",
    "                    for ind_insight in insight_soup:\n",
    "                        all_insight.append(ind_insight.text.strip())\n",
    "                \n",
    "                    insight = '|'.join(all_insight)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                print(\"ASIN, Model Number, manufacturer_name, generic_name\", asin, model_number, manufacturer_name, generic_name)\n",
    "            \n",
    "                try:\n",
    "                    review_link = soup2.find('a', attrs={\"data-hook\": \"see-all-reviews-link-foot\"}).get('href')\n",
    "                    review_link = \"https://www.amazon.in/\" + review_link\n",
    "                    \n",
    "                except:\n",
    "                    print(\"❌ No valid Review link found in this product.\")\n",
    "                    product_detail_list.append([asin, model_number, manufacturer_name, generic_name,\n",
    "                    prod_title, price, overall_rating, rating_count, None, bought_last_month, product_link, customer_say, insight,\n",
    "                    None, None, None,\n",
    "                    None, False, None,   \n",
    "                    None                 \n",
    "                ])\n",
    "    \n",
    "                    continue\n",
    "    \n",
    "                if review_link not in visited_review_links:\n",
    "                    visited_review_links.add(review_link)\n",
    "                    browser.get(review_link)\n",
    "                    time.sleep(random.uniform(2, 4))\n",
    "                \n",
    "                else:\n",
    "                    print(\"Same Product\")\n",
    "                    continue\n",
    "            \n",
    "                while True:\n",
    "                    scroll_pause_time = random.uniform(1.8, 2.5)\n",
    "                    max_scrolls = 10\n",
    "                    \n",
    "                    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                    \n",
    "                    for _ in range(max_scrolls):\n",
    "                        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                        time.sleep(scroll_pause_time)\n",
    "                        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                        if new_height == last_height:\n",
    "                            break\n",
    "                        last_height = new_height\n",
    "\n",
    "                    soup4 = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "                    review_count = None\n",
    "                    \n",
    "                    try:\n",
    "                        review_count = soup4.find('div', attrs={\"data-hook\":\"cr-filter-info-review-rating-count\"}).text.strip().split()[0].strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "                    all_review = soup4.find_all('li', attrs={\"data-hook\": \"review\"})\n",
    "            \n",
    "                    for ind_review in all_review:\n",
    "                        try:\n",
    "                            rating = ind_review.find('h5').find('i', attrs={\"data-hook\": \"review-star-rating\"}).text.split()[0].strip()\n",
    "                        except:\n",
    "                            rating = None\n",
    "            \n",
    "                        try:\n",
    "                            review_title = ind_review.find('h5').find('span', class_=None).text.strip()\n",
    "                        except:\n",
    "                            review_title = None\n",
    "            \n",
    "                        try:\n",
    "                            review_date = ind_review.find('span', attrs={\"data-hook\": \"review-date\"}).text.strip()\n",
    "                        except:\n",
    "                            review_date = None\n",
    "            \n",
    "                        try:\n",
    "                            format_tag = ind_review.find('a', attrs={\"data-hook\": \"format-strip\"})\n",
    "                            product_desc = \"|\".join([\n",
    "                                t.strip() for t in format_tag.find_all(text=True, recursive=False)\n",
    "                            ]) if format_tag else None\n",
    "                        except:\n",
    "                            product_desc = None\n",
    "            \n",
    "                        try:\n",
    "                            verified_purchase = ind_review.find('span', attrs={\"data-hook\": \"avp-badge\"}) is not None\n",
    "                        except:\n",
    "                            verified_purchase = False\n",
    "            \n",
    "                        try:\n",
    "                            review_text = ind_review.find('span', attrs={\"data-hook\": \"review-body\"}) \\\n",
    "                                                     .find('span', class_=None).text.strip()\n",
    "                        except:\n",
    "                            review_text = None\n",
    "            \n",
    "                        try:\n",
    "                            helpful = ind_review.find('span', attrs={\"data-hook\": \"helpful-vote-statement\"})\n",
    "                            helpful_votes = helpful.text.split()[0].strip() if helpful else \"0\"\n",
    "                        except:\n",
    "                            helpful_votes = None\n",
    "            \n",
    "                        product_detail_list.append([asin, model_number, manufacturer_name, generic_name,\n",
    "                            prod_title, price, overall_rating, rating_count, review_count, bought_last_month, product_link, customer_say, insight,\n",
    "                            rating, review_title, review_date,\n",
    "                            product_desc, verified_purchase, review_text, helpful_votes\n",
    "                        ])\n",
    "            \n",
    "                    try:\n",
    "                        next_li = browser.find_element(By.CLASS_NAME, 'a-last')\n",
    "                        if \"a-disabled\" in next_li.get_attribute(\"class\"):\n",
    "                            print(\"✅ Reached last page of reviews.\")\n",
    "                            break\n",
    "                        else:\n",
    "                            try:\n",
    "                                next_button = next_li.find_element(By.TAG_NAME, 'a')\n",
    "                                browser.execute_script(\"arguments[0].click();\", next_button)\n",
    "                                time.sleep(random.uniform(2, 4))\n",
    "                            except Exception as e:\n",
    "                                print(\"⚠️ Couldn't click the next button:\", e)\n",
    "                                break\n",
    "                    except NoSuchElementException:\n",
    "                        print(\"✅ No pagination (only one page of reviews).\")\n",
    "                        break\n",
    "            except:\n",
    "                print(\"⚠️ Error in processing product:\", e)\n",
    "                continue\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Scraping stopped by user (Ctrl+C).\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Unexpected Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae4b85-19bd-43fc-b94f-fa8153d3b615",
   "metadata": {},
   "source": [
    "> ⚠️ Output of the above cell has been removed to keep the notebook readable. Below is sample output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5df71-7e63-4e34-b6c9-7a6163b37ff0",
   "metadata": {},
   "source": [
    "Enter product you want to search (like Mobile, laptop ....) -  laptop\r\n",
    "\r\n",
    "✅ You can search by Index or Brand Name\r\n",
    "\r\n",
    "Index                 Brand Name  \r\n",
    "    0                        all  \r\n",
    "    1                         HP  \r\n",
    "    2                     Lenovo  \r\n",
    "    3                       ASUS  \r\n",
    "    4                       acer  \r\n",
    "    5                       Dell  \r\n",
    "    6                      Apple  \r\n",
    "    7                        MSI  \r\n",
    "    8                    Samsung  \r\n",
    "    9                  Microsoft  \r\n",
    "   10                   GIGABYTE  \r\n",
    "   11                      Dyazo  \r\n",
    "   12                    Lapcare  \r\n",
    "   13                  ZEBRONICS  \r\n",
    "   14           ah arctic hunter  \r\n",
    "   15              amazon basics  \r\n",
    "   16                        rts  \r\n",
    "   17                  Stuffcool  \r\n",
    "   18                  uppercase  \r\n",
    "   19                   Logitech  \r\n",
    "   20                     COSMUS  \r\n",
    "   21        HAMMONDS FLYCATCHER  \r\n",
    "   22                   MOKOBARA  \r\n",
    "   23                     Sounce  \r\n",
    "   24                 Portronics  \r\n",
    "   25                      Shure  \r\n",
    "   26                    Crucial  \r\n",
    "   27               GADGETS WRAP  \r\n",
    "   28                       EUME  \r\n",
    "   29                   WildHorn  \r\n",
    "   30              THE CLOWNFISH  \r\n",
    "   31 LS LAPSTER Quality Assured  \r\n",
    "   32             SWISS MILITARY  \r\n",
    "   33                    Ambrane  \r\n",
    "   34                     Belkin  \r\n",
    "   35                       BenQ  \r\n",
    "   36                      Anker  \r\n",
    "   37                     Tukzer  \r\n",
    "   38                Ant Esports  \r\n",
    "   39                       Gear  \r\n",
    "   40                     Safari  \r\n",
    "\r\n",
    "Enter Index or Brand Name you want to search -  apple, hp, lenovo, msi, dell  \r\n",
    "Brand Name -  apple  \r\n",
    "Brand Name -  Lenovo  \r\n",
    "Brand Name -  Dell  \r\n",
    "Brand Name -  HP  \r\n",
    "Brand Name -  MSI  \r\n",
    "\r\n",
    "last page 20  \r\n",
    "Page Url https://www.amazon.in/s?k=laptop&rh=p_123%3A110955%257C241862%257C308445%257C378555%257C391242&dc&qid=1752467357&rnid=91049095031&ref=sr_nr_p_123_7&ds=v1%3Au0BxVt3pN1g%2BfNoWZv84AIVlLFAt3%2BlXjGpykMocOC4&page=1  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_na for t in format_tag.find_all(text=True, recursive=False)  \r\n",
    "✅ Reached last page of reviews.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0F8P4Y7VF C08Q6PA HP Laptop  \r\n",
    "❌ No valid Review link found in this product.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0DP7BZ8FD 14IAH8 Lenovo Laptop  \r\n",
    "✅ Reached last page of reviews.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0D3HG5CMG 9D3M8PA HP Laptop  \r\n",
    "✅ Reached last page of reviews.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0FCD9LKLZ 250 G9 HP Business Laptop  \r\n",
    "✅ No pagination (only one page of reviews).  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0F32ZBDNJ Intel Core i7-1255U Upto 4.70Ghz Lenovo Laptop  \r\n",
    "✅ Reached last page of reviews.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B08N5W4NNB MGN63HN/A Apple Laptop  \r\n",
    "✅ Reached last page of reviews.  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0DZJ262NX 7535HS Lenovo Laptop  \r\n",
    "✅ No pagination (only one page of reviews).  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0FFGWWHBP 240 G10 hp Notebook Laptop  \r\n",
    "✅ No pagination (only one page of reviews).  \r\n",
    "\r\n",
    "ASIN, Model Number, manufacturer_name, generic_name B0F2162VGQ 15IRH10 Lenovo Laptop  \r\n",
    "✅ Reached last page of reviews.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3859495c-e746-4360-8d5c-69edcc1ee223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>all</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HP</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>acer</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Dell</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Apple</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>MSI</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>GIGABYTE</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Dyazo</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Lapcare</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>ZEBRONICS</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ah arctic hunter</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>amazon basics</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>rts</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Stuffcool</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>uppercase</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>COSMUS</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>HAMMONDS FLYCATCHER</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>MOKOBARA</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Sounce</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Portronics</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Shure</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Crucial</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>GADGETS WRAP</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>EUME</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>WildHorn</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>THE CLOWNFISH</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>LS LAPSTER Quality Assured</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>SWISS MILITARY</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Ambrane</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Belkin</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>BenQ</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Anker</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Tukzer</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Ant Esports</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Gear</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Safari</td>\n",
       "      <td>https://www.amazon.in/s?k=laptop&amp;rh=p_123%3A64...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                  Brand Name  \\\n",
       "0      0                         all   \n",
       "1      1                          HP   \n",
       "2      2                      Lenovo   \n",
       "3      3                        ASUS   \n",
       "4      4                        acer   \n",
       "5      5                        Dell   \n",
       "6      6                       Apple   \n",
       "7      7                         MSI   \n",
       "8      8                     Samsung   \n",
       "9      9                   Microsoft   \n",
       "10    10                    GIGABYTE   \n",
       "11    11                       Dyazo   \n",
       "12    12                     Lapcare   \n",
       "13    13                   ZEBRONICS   \n",
       "14    14            ah arctic hunter   \n",
       "15    15               amazon basics   \n",
       "16    16                         rts   \n",
       "17    17                   Stuffcool   \n",
       "18    18                   uppercase   \n",
       "19    19                    Logitech   \n",
       "20    20                      COSMUS   \n",
       "21    21         HAMMONDS FLYCATCHER   \n",
       "22    22                    MOKOBARA   \n",
       "23    23                      Sounce   \n",
       "24    24                  Portronics   \n",
       "25    25                       Shure   \n",
       "26    26                     Crucial   \n",
       "27    27                GADGETS WRAP   \n",
       "28    28                        EUME   \n",
       "29    29                    WildHorn   \n",
       "30    30               THE CLOWNFISH   \n",
       "31    31  LS LAPSTER Quality Assured   \n",
       "32    32              SWISS MILITARY   \n",
       "33    33                     Ambrane   \n",
       "34    34                      Belkin   \n",
       "35    35                        BenQ   \n",
       "36    36                       Anker   \n",
       "37    37                      Tukzer   \n",
       "38    38                 Ant Esports   \n",
       "39    39                        Gear   \n",
       "40    40                      Safari   \n",
       "\n",
       "                                                  Url  \n",
       "0                    https://www.amazon.in/s?k=laptop  \n",
       "1   https://www.amazon.in/s?k=laptop&rh=p_123%3A30...  \n",
       "2   https://www.amazon.in/s?k=laptop&rh=p_123%3A39...  \n",
       "3   https://www.amazon.in/s?k=laptop&rh=p_123%3A21...  \n",
       "4   https://www.amazon.in/s?k=laptop&rh=p_123%3A24...  \n",
       "5   https://www.amazon.in/s?k=laptop&rh=p_123%3A24...  \n",
       "6   https://www.amazon.in/s?k=laptop&rh=p_123%3A11...  \n",
       "7   https://www.amazon.in/s?k=laptop&rh=p_123%3A37...  \n",
       "8   https://www.amazon.in/s?k=laptop&rh=p_123%3A46...  \n",
       "9   https://www.amazon.in/s?k=laptop&rh=p_123%3A42...  \n",
       "10  https://www.amazon.in/s?k=laptop&rh=p_123%3A24...  \n",
       "11  https://www.amazon.in/s?k=laptop&rh=p_123%3A43...  \n",
       "12  https://www.amazon.in/s?k=laptop&rh=p_123%3A45...  \n",
       "13  https://www.amazon.in/s?k=laptop&rh=p_123%3A39...  \n",
       "14  https://www.amazon.in/s?k=laptop&rh=p_123%3A55...  \n",
       "15  https://www.amazon.in/s?k=laptop&rh=p_123%3A23...  \n",
       "16  https://www.amazon.in/s?k=laptop&rh=p_123%3A33...  \n",
       "17  https://www.amazon.in/s?k=laptop&rh=p_123%3A45...  \n",
       "18  https://www.amazon.in/s?k=laptop&rh=p_123%3A20...  \n",
       "19  https://www.amazon.in/s?k=laptop&rh=p_123%3A21...  \n",
       "20  https://www.amazon.in/s?k=laptop&rh=p_123%3A44...  \n",
       "21  https://www.amazon.in/s?k=laptop&rh=p_123%3A47...  \n",
       "22  https://www.amazon.in/s?k=laptop&rh=p_123%3A65...  \n",
       "23  https://www.amazon.in/s?k=laptop&rh=p_123%3A65...  \n",
       "24  https://www.amazon.in/s?k=laptop&rh=p_123%3A41...  \n",
       "25  https://www.amazon.in/s?k=laptop&rh=p_123%3A23...  \n",
       "26  https://www.amazon.in/s?k=laptop&rh=p_123%3A24...  \n",
       "27  https://www.amazon.in/s?k=laptop&rh=p_123%3A33...  \n",
       "28  https://www.amazon.in/s?k=laptop&rh=p_123%3A33...  \n",
       "29  https://www.amazon.in/s?k=laptop&rh=p_123%3A44...  \n",
       "30  https://www.amazon.in/s?k=laptop&rh=p_123%3A35...  \n",
       "31  https://www.amazon.in/s?k=laptop&rh=p_123%3A46...  \n",
       "32  https://www.amazon.in/s?k=laptop&rh=p_123%3A60...  \n",
       "33  https://www.amazon.in/s?k=laptop&rh=p_123%3A10...  \n",
       "34  https://www.amazon.in/s?k=laptop&rh=p_123%3A15...  \n",
       "35  https://www.amazon.in/s?k=laptop&rh=p_123%3A22...  \n",
       "36  https://www.amazon.in/s?k=laptop&rh=p_123%3A32...  \n",
       "37  https://www.amazon.in/s?k=laptop&rh=p_123%3A38...  \n",
       "38  https://www.amazon.in/s?k=laptop&rh=p_123%3A61...  \n",
       "39  https://www.amazon.in/s?k=laptop&rh=p_123%3A62...  \n",
       "40  https://www.amazon.in/s?k=laptop&rh=p_123%3A64...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a62603-c8d5-49c2-a212-04c6ba5a2a69",
   "metadata": {},
   "source": [
    "## 📊 Creating DataFrame from Scraped Data\r\n",
    "\r\n",
    "After scraping product and review information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817288f5-ccd1-4df0-934b-2f8f27e0d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_1 = [\"ASIN\", \"Model Number\", \"Manufacturer Name\", \"Generic Name\",\n",
    "    \"Product Title\", \"Price\", \"Overall Rating\", \"Rating Count\", \"Review Count\", \"Bought L Month\", \"Product Link\", \"Customer Say\", \"Insight\",\n",
    "    \"Individual Rating\", \"Review Title\", \"Review Date\",\n",
    "    \"Product Description\", \"Verified Purchase\", \"Review Text\", \"Helpful Votes\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data = product_detail_list, columns=columns_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38b4556-d091-45a8-a999-491c23886125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>Manufacturer Name</th>\n",
       "      <th>Generic Name</th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Review Count</th>\n",
       "      <th>Bought L Month</th>\n",
       "      <th>Product Link</th>\n",
       "      <th>Customer Say</th>\n",
       "      <th>Insight</th>\n",
       "      <th>Individual Rating</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Verified Purchase</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Helpful Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0DZDC247V</td>\n",
       "      <td>MW0Y3HN/A</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Air</td>\n",
       "      <td>Apple 2025 MacBook Air (13-inch, Apple M4 chip...</td>\n",
       "      <td>89,990.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>300+</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fast and Powerful!</td>\n",
       "      <td>Reviewed in India on 19 April 2025</td>\n",
       "      <td>Colour: Starlight|Size: 16GB Unified Memory|St...</td>\n",
       "      <td>True</td>\n",
       "      <td>I recently purchased the MacBook M4 with 512GB...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0DZDC247V</td>\n",
       "      <td>MW0Y3HN/A</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Air</td>\n",
       "      <td>Apple 2025 MacBook Air (13-inch, Apple M4 chip...</td>\n",
       "      <td>89,990.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>300+</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Elevate Your Productivity with the Perfect Laptop</td>\n",
       "      <td>Reviewed in India on 4 April 2025</td>\n",
       "      <td>Colour: Midnight|Size: 16GB Unified Memory|Sty...</td>\n",
       "      <td>True</td>\n",
       "      <td>I placed the order on March 28th and received ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0DZDC247V</td>\n",
       "      <td>MW0Y3HN/A</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Air</td>\n",
       "      <td>Apple 2025 MacBook Air (13-inch, Apple M4 chip...</td>\n",
       "      <td>89,990.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>300+</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great build quality, good for everyday/office use</td>\n",
       "      <td>Reviewed in India on 9 May 2025</td>\n",
       "      <td>Colour: Sky Blue|Size: 16GB Unified Memory|Sty...</td>\n",
       "      <td>True</td>\n",
       "      <td>New to the apple ecosystem. Every single apple...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0DZDC247V</td>\n",
       "      <td>MW0Y3HN/A</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Air</td>\n",
       "      <td>Apple 2025 MacBook Air (13-inch, Apple M4 chip...</td>\n",
       "      <td>89,990.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>300+</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sleek and super fast</td>\n",
       "      <td>Reviewed in India on 4 July 2025</td>\n",
       "      <td>Colour: Starlight|Size: 16GB Unified Memory|St...</td>\n",
       "      <td>True</td>\n",
       "      <td>Very easy to use , has met my expectations</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0DZDC247V</td>\n",
       "      <td>MW0Y3HN/A</td>\n",
       "      <td>Apple</td>\n",
       "      <td>MacBook Air</td>\n",
       "      <td>Apple 2025 MacBook Air (13-inch, Apple M4 chip...</td>\n",
       "      <td>89,990.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>300+</td>\n",
       "      <td>https://www.amazon.in/sspa/click?ie=UTF8&amp;spc=M...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Overwhelmed with my purchase</td>\n",
       "      <td>Reviewed in India on 19 April 2025</td>\n",
       "      <td>Colour: Starlight|Size: 16GB Unified Memory|St...</td>\n",
       "      <td>True</td>\n",
       "      <td>Just got it 2 days ago. So far, just overwhelm...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN Model Number Manufacturer Name Generic Name  \\\n",
       "0  B0DZDC247V    MW0Y3HN/A             Apple  MacBook Air   \n",
       "1  B0DZDC247V    MW0Y3HN/A             Apple  MacBook Air   \n",
       "2  B0DZDC247V    MW0Y3HN/A             Apple  MacBook Air   \n",
       "3  B0DZDC247V    MW0Y3HN/A             Apple  MacBook Air   \n",
       "4  B0DZDC247V    MW0Y3HN/A             Apple  MacBook Air   \n",
       "\n",
       "                                       Product Title    Price Overall Rating  \\\n",
       "0  Apple 2025 MacBook Air (13-inch, Apple M4 chip...  89,990.            4.5   \n",
       "1  Apple 2025 MacBook Air (13-inch, Apple M4 chip...  89,990.            4.5   \n",
       "2  Apple 2025 MacBook Air (13-inch, Apple M4 chip...  89,990.            4.5   \n",
       "3  Apple 2025 MacBook Air (13-inch, Apple M4 chip...  89,990.            4.5   \n",
       "4  Apple 2025 MacBook Air (13-inch, Apple M4 chip...  89,990.            4.5   \n",
       "\n",
       "  Rating Count Review Count Bought L Month  \\\n",
       "0           33           15           300+   \n",
       "1           33           15           300+   \n",
       "2           33           15           300+   \n",
       "3           33           15           300+   \n",
       "4           33           15           300+   \n",
       "\n",
       "                                        Product Link Customer Say Insight  \\\n",
       "0  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...         None    None   \n",
       "1  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...         None    None   \n",
       "2  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...         None    None   \n",
       "3  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...         None    None   \n",
       "4  https://www.amazon.in/sspa/click?ie=UTF8&spc=M...         None    None   \n",
       "\n",
       "  Individual Rating                                       Review Title  \\\n",
       "0               5.0                                 Fast and Powerful!   \n",
       "1               5.0  Elevate Your Productivity with the Perfect Laptop   \n",
       "2               5.0  Great build quality, good for everyday/office use   \n",
       "3               5.0                               Sleek and super fast   \n",
       "4               5.0                       Overwhelmed with my purchase   \n",
       "\n",
       "                          Review Date  \\\n",
       "0  Reviewed in India on 19 April 2025   \n",
       "1   Reviewed in India on 4 April 2025   \n",
       "2     Reviewed in India on 9 May 2025   \n",
       "3    Reviewed in India on 4 July 2025   \n",
       "4  Reviewed in India on 19 April 2025   \n",
       "\n",
       "                                 Product Description  Verified Purchase  \\\n",
       "0  Colour: Starlight|Size: 16GB Unified Memory|St...               True   \n",
       "1  Colour: Midnight|Size: 16GB Unified Memory|Sty...               True   \n",
       "2  Colour: Sky Blue|Size: 16GB Unified Memory|Sty...               True   \n",
       "3  Colour: Starlight|Size: 16GB Unified Memory|St...               True   \n",
       "4  Colour: Starlight|Size: 16GB Unified Memory|St...               True   \n",
       "\n",
       "                                         Review Text Helpful Votes  \n",
       "0  I recently purchased the MacBook M4 with 512GB...            38  \n",
       "1  I placed the order on March 28th and received ...           118  \n",
       "2  New to the apple ecosystem. Every single apple...             4  \n",
       "3         Very easy to use , has met my expectations           One  \n",
       "4  Just got it 2 days ago. So far, just overwhelm...            25  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9e7f11-7c4d-4d33-b7c6-50d1b6e8b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('1. product_laptop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a522a95-c1d1-4956-b908-b46e8cc90a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
